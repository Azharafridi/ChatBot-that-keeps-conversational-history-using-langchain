{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## laoding all the environment variables\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E2F7A72410>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E2F7A737C0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\",api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Azhar! It's nice to meet you.  \\n\\nThat's awesome! Being a Gen AI engineer is such a fascinating field. What kind of projects are you working on? \\n\\nI'm always eager to learn more about the work people are doing with AI. ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 22, 'total_tokens': 84, 'completion_time': 0.112727273, 'prompt_time': 0.002120865, 'queue_time': 0.018609724, 'total_time': 0.114848138}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7e5848b4-5842-4ca7-b0ac-292d699976a2-0', usage_metadata={'input_tokens': 22, 'output_tokens': 62, 'total_tokens': 84})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is azhar and i am Gen AI engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Azhar, and that you are a Gen AI engineer! \\n\\nIs there anything else you'd like to tell me about yourself or your work? ðŸ˜„  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 102, 'total_tokens': 143, 'completion_time': 0.074545455, 'prompt_time': 0.005100459, 'queue_time': 0.016175630000000003, 'total_time': 0.079645914}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-de16b2f4-b7fa-4dfa-a240-4f67b4b92f93-0', usage_metadata={'input_tokens': 102, 'output_tokens': 41, 'total_tokens': 143})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is azhar and i am Gen AI engineer\"),\n",
    "        AIMessage(content=\"Hi Azhar! It's nice to meet you.  \\n\\nThat's awesome! Being a Gen AI engineer is such a fascinating field. What kind of projects are you working on? \\n\\nI'm always eager to learn more about the work people are doing with AI. ðŸ˜Š\\n\"),\n",
    "        HumanMessage(content=\"Hey whats my name and wat do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### message history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() \n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is azhar and i am Gen AI engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Azhar! It's nice to meet you. \\n\\nBeing a Gen AI engineer is a fascinating field. What kind of projects are you working on these days?  Are you focused on text generation, image synthesis, something else entirely? I'm always eager to learn more about the innovative work being done in this space.  ðŸ˜Š \\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Azhar.  ðŸ˜Š \\n\\nI remembered from our first introduction!  \\n\\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 198, 'total_tokens': 220, 'completion_time': 0.04, 'prompt_time': 0.0120653, 'queue_time': 0.180608758, 'total_time': 0.0520653}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-09889c33-3e7e-443a-9f9b-97323b8509d6-0', usage_metadata={'input_tokens': 198, 'output_tokens': 22, 'total_tokens': 220})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I have no access to personal information about you, including your name. If you'd like to tell me your name, I'd be happy to know!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## change the config -->session\n",
    "config1 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Afridi! ðŸ‘‹ \\n\\nHow can I help you today? ðŸ˜Š  \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"my name is afridi\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Afridi. ðŸ˜Š  \n",
      "\n",
      "I remember!  \n",
      "\n",
      "Is there anything else I can help you with?  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "working with prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are a helpful assistant.Answer all the question to the nest of your ability\"\n",
    "            ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Azhar, it's nice to meet you!\\n\\nI'm ready to answer your questions to the best of my ability. What can I help you with today? ðŸ˜Š  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 31, 'total_tokens': 72, 'completion_time': 0.074545455, 'prompt_time': 0.002788413, 'queue_time': 0.020458625, 'total_time': 0.077333868}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b4cb97f4-1f03-4720-bac2-fa1edb23a991-0', usage_metadata={'input_tokens': 31, 'output_tokens': 41, 'total_tokens': 72})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hey my name is azhar\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Azhar! It's nice to meet you.\\n\\nHow can I help you today? ðŸ˜Š  \\n\\nI'm ready for any questions you have!  \\n\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response = with_message_history.invoke([HumanMessage(content=\"Hey my name is azhar\")],\n",
    "                                        config=config\n",
    "                                        )\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are a helpful assistant.Answer all the question to the nest of your ability\"\n",
    "            ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    "\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Azhar, it's nice to meet you!\\n\\nI'm happy to help with any questions you have. Just ask away!  ðŸ˜Š \\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is azhar\")], \"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Azhar!  \\n\\nIt's nice to meet you.  \\n\\nWhat can I do for you today? ðŸ˜Š  \\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi, i am azhar\")], \"language\": \"english\"},\n",
    "    config=config\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Azhar. ðŸ˜Š \\n\\nHow can I help you further?  \\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"what's my name?\")], \"language\": \"english\"},\n",
    "    config=config\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage the conversation History"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
